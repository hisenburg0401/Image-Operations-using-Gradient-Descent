# Brief about the code:

Here, we have the original image and we want to factorize that image into two matrices W and H such that the product of these two matrices gives the original image. However, the image generated by the product of these two matrices is not the exact same as the original image. So, we want to minimize the error between the original and the reconstructed image. We are using Gradient Descent method to solve this factorization problem. The function `factorize()` is defined to solve the matrix factorization problem. The function takes the following inputs:

- `A`: The matrix to be factorized
- `k`: The number of latent features
- `device`: The device to be used for computation (like cpu or cuda (for gpu))

Note: here, lambda_reg is also taken as a input but is not used in the code as we are not using any regularization term in the loss function so we have takken the value of lambda_reg=0 everywhere in this part.

The function returns the following outputs:

- `W`: The matrix of user features
- `H`: The matrix of item features


# Observations:

Here, as we can see from the reconstructed images that if the number of colours in the image are less then even less number of features (rank) is also giving a very good results. But, if the number of colours in the image are more then we need to take more number of features to get the exact image. This is happening because if the number of colours are less then the trend is very clear and is very easy to predict but if we increase the number of colours then the trend becomes very difficult to predict and requires more features to predict the exact image. So, we can say that the number of features required to predict the exact image is directly proportional to the number of colours in the image. 

Here, another observation which can be made is that when we were using all values of the image to store the image then for the patch we were storing total of 50*50*3 values and each consuming total of 32 bits adding up to a total of 240000 bits. But, when we are using the factorization method then we are storing the values of W and H which are of the size 50*10*3 and 10*50*3 (in case of rank=10) which are consuming a total of 50*10*3 + 10*50*3 = 3000 bits. So, we can see that the factorization method is very efficient in terms of memory as compared to the original image.
